{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En este notebook queda registrado el código mediante el que fueron creadas las tablas de la base de datos de mysql alojada en AWS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos las funciones mediantes las que atacar a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la librerías y variables necesarias\n",
    "import mysql.connector\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from flask import Flask, jsonify, request\n",
    "import pickle\n",
    "import os\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "\"\"\"Definimos las variables generales para atacar la base de datos\"\"\"\n",
    "#Definimos un cursor con el que atacar a la DB\n",
    "cnx = mysql.connector.connect(\n",
    "    user=\"admin\",\n",
    "    password=\"admin123\",\n",
    "    host=\"test-db.cze2nnbbx5pc.eu-west-3.rds.amazonaws.com\",\n",
    "    database=\"prueba\")\n",
    "cursor = cnx.cursor()\n",
    "#Definimos una función mediante la que ejecutar las querys\n",
    "def make_query(code):\n",
    "    cursor.execute(code)\n",
    "    results = cursor.fetchall()\n",
    "    cnx.commit()\n",
    "    return(results)\n",
    "#Definimos una función mediante la que ejecutar las querys devolviendo un dataframe\n",
    "def make_query_dataframe(code):\n",
    "    cursor.execute(code)\n",
    "    results = cursor.fetchall()\n",
    "    column_names = [desc[0] for desc in cursor.description]  # Obtener los nombres de las columnas\n",
    "    df = pd.DataFrame(results, columns=column_names)  # Crear el DataFrame\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. employee_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamos los datos del CSV\n",
    "datos_raw=pd.read_csv(\"hr_names.csv\", index_col=\"EmployeeID\")\n",
    "data=datos_raw.drop(columns=[\"EmployeeCount\",\"Over18\",\"StandardHours\"])\n",
    "#Cambiamos el nombre de las columnas\n",
    "order=['Name','hrs', 'JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction',\n",
    "       'JobSatisfaction', 'WorkLifeBalance', 'Age', 'Attrition',\n",
    "       'BusinessTravel', 'Department', 'DistanceFromHome', 'Education',\n",
    "       'EducationField', 'Gender', 'JobLevel', 'JobRole', 'MaritalStatus',\n",
    "       'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
    "       'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager'\n",
    "       ]\n",
    "data = data.reindex(columns=order)\n",
    "#Creamos la query para la creación de la tabla y definimos los tipos de campos\n",
    "make_query(\"\"\"CREATE TABLE employee_raw (\n",
    "    id_employee INT NOT NULL,\n",
    "    name VARCHAR(50),\n",
    "    hours DECIMAL(4,2),\n",
    "    involvement VARCHAR(50),\n",
    "    performance VARCHAR(50),\n",
    "    environment VARCHAR(50),\n",
    "    satisfaction VARCHAR(50),\n",
    "    life_balance VARCHAR(50),\n",
    "    age INT,\n",
    "    attrition VARCHAR(50),\n",
    "    travel VARCHAR(50),\n",
    "    department VARCHAR(50),\n",
    "    distance_home INT,\n",
    "    education VARCHAR(50),\n",
    "    education_field VARCHAR(50),\n",
    "    gender VARCHAR(50),\n",
    "    job_level INT,\n",
    "    role VARCHAR(50),\n",
    "    marital_status VARCHAR(50),\n",
    "    income INT,\n",
    "    previous_companies INT,\n",
    "    salary_hike INT,\n",
    "    stock_option INT,\n",
    "    total_working_years INT,\n",
    "    training_ly INT,\n",
    "    years_company INT,\n",
    "    last_promotion INT,\n",
    "    years_curr_manager INT,\n",
    "    PRIMARY KEY (id_employee))\"\"\"\n",
    ")\n",
    "data=data.reset_index()\n",
    "# Ejecutamos la query fila por fila para acelerar el proceso\n",
    "for row in data.itertuples(index=False):\n",
    "    values = ', '.join(\"'\" + str(value).replace(\"'\", \"''\") + \"'\" for value in row)\n",
    "    query = f\"INSERT INTO employee_raw VALUES ({values})\"\n",
    "    cursor.execute(query)\n",
    "    print(row)\n",
    "# Confirmar los cambios en la base de datos\n",
    "cnx.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. current_employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una query para traer a todos los trabajadores raw\n",
    "datos_base_datos=make_query_dataframe(\"SELECT * FROM prueba.employee_raw;\")\n",
    "#Seleccionamos a los trabajadores actuales\n",
    "employess_actuales=datos_base_datos[datos_base_datos[\"attrition\"]==\"No\"].copy()\n",
    "employess_actuales=employess_actuales.drop(columns=\"id_employee\").reset_index().drop(columns=\"index\").reset_index().rename(columns={'index': 'id_employee'})\n",
    "\n",
    "#Creamos la query para la creación de la tabla y definimos los tipos de campos\n",
    "make_query(\"\"\"CREATE TABLE current_employees (\n",
    "    id_employee INT,\n",
    "    name VARCHAR(50),\n",
    "    hours DECIMAL(4,2),\n",
    "    involvement VARCHAR(50),\n",
    "    performance VARCHAR(50),\n",
    "    environment VARCHAR(50),\n",
    "    satisfaction VARCHAR(50),\n",
    "    life_balance VARCHAR(50),\n",
    "    age INT,\n",
    "    attrition VARCHAR(50),\n",
    "    travel VARCHAR(50),\n",
    "    department VARCHAR(50),\n",
    "    distance_home INT,\n",
    "    education VARCHAR(50),\n",
    "    education_field VARCHAR(50),\n",
    "    gender VARCHAR(50),\n",
    "    job_level INT,\n",
    "    role VARCHAR(50),\n",
    "    marital_status VARCHAR(50),\n",
    "    income INT,\n",
    "    previous_companies INT,\n",
    "    salary_hike INT,\n",
    "    stock_option INT,\n",
    "    total_working_years INT,\n",
    "    training_ly INT,\n",
    "    years_company INT,\n",
    "    last_promotion INT,\n",
    "    years_curr_manager INT,\n",
    "    PRIMARY KEY (id_employee))\"\"\"\n",
    ")\n",
    "\n",
    "# Cargar los datos del CSV a la tabla\n",
    "for row in employess_actuales.itertuples(index=False):\n",
    "    values = ', '.join(\"'\" + str(value).replace(\"'\", \"''\") + \"'\" for value in row)\n",
    "    query = f\"INSERT INTO current_employees VALUES ({values})\"\n",
    "    cursor.execute(query)\n",
    "    print(row)\n",
    "# Confirmar los cambios en la base de datos\n",
    "cnx.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "1205 (HY000): Lock wait timeout exceeded; try restarting transaction",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mgilj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    612\u001b[0m                 \u001b[0mraw_as_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw_as_string\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m                 \u001b[0mquery_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m             )\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: Lock wait timeout exceeded; try restarting transaction",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20900\\489594393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"''\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"'\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"INSERT INTO predictions VALUES ({values})\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Confirmar los cambios en la base de datos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgilj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\mysql\\connector\\cursor_cext.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    332\u001b[0m                 \u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m                 \u001b[0mbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffered\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m                 \u001b[0mraw_as_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_as_string\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m             )\n\u001b[0;32m    336\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mgilj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    616\u001b[0m             raise get_mysql_exception(\n\u001b[0;32m    617\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqlstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m             ) from err\n\u001b[0m\u001b[0;32m    619\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             addr = (\n",
      "\u001b[1;31mDatabaseError\u001b[0m: 1205 (HY000): Lock wait timeout exceeded; try restarting transaction"
     ]
    }
   ],
   "source": [
    "# make_query(\"\"\"CREATE TABLE borrar_predictions (\n",
    "#     id_employee INT,\n",
    "#     months_left DECIMAL(8,2),\n",
    "#     PRIMARY KEY (id_employee))\"\"\"\n",
    "# )\n",
    "\n",
    "numeros_aleatorios_prueba=np.random.randint(1,36,3698)\n",
    "df=pd.DataFrame(numeros_aleatorios_prueba).rename(columns={0:\"months_left\"}).reset_index()\n",
    "# Ejecutamos la query fila por fila para acelerar el proceso\n",
    "for row in df.itertuples(index=False):\n",
    "    values = ', '.join(\"'\" + str(value).replace(\"'\", \"''\") + \"'\" for value in row)\n",
    "    query = f\"INSERT INTO predictions VALUES ({values})\"\n",
    "    cursor.execute(query)\n",
    "    print(row)\n",
    "# Confirmar los cambios en la base de datos\n",
    "cnx.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. replacement_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de la tabla del tiempo medio necesario para reemplazar a un puesto determinado\n",
    "data = {\n",
    "    'JobRole': [\n",
    "        'Manufacturing Director',\n",
    "        'Laboratory Technician',\n",
    "        'Research Director',\n",
    "        'Sales Representative',\n",
    "        'Sales Executive',\n",
    "        'Research Scientist',\n",
    "        'Manager',\n",
    "        'Healthcare Representative',\n",
    "        'Human Resources'\n",
    "    ],\n",
    "    'Avg replacement time (monthly)': [8.0, 4.5, 8.0, 4.5, 8.0, 4.5, 8.0, 4.5, 4.5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df=df.reset_index()\n",
    "\n",
    "\n",
    "# Ejecutamos la query fila por fila para acelerar el proceso\n",
    "for row in df.itertuples(index=False):\n",
    "    values = ', '.join(\"'\" + str(value).replace(\"'\", \"''\") + \"'\" for value in row)\n",
    "    query = f\"INSERT INTO replacement_time VALUES ({values})\"\n",
    "    cursor.execute(query)\n",
    "    print(row)\n",
    "# Confirmar los cambios en la base de datos\n",
    "cnx.commit()\n",
    "# Cerrar el cursor y la conexión\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Procedimiento creado para la actualización tras editar la tabla de predicciones\n",
    "DELIMITER //\n",
    "\n",
    "CREATE PROCEDURE actualizacion_predictions()\n",
    "BEGIN\n",
    "    -- Crear la tabla prueba_miguel si no existe\n",
    "    CREATE TABLE IF NOT EXISTS prueba_miguel (\n",
    "        id_employee INT,\n",
    "        replacement_cost DECIMAL(10, 2),\n",
    "        months_left INT,\n",
    "        risk VARCHAR(10)\n",
    "    );\n",
    "\n",
    "    -- Eliminar todos los datos existentes en la tabla prueba_miguel\n",
    "    DELETE FROM prueba_miguel;\n",
    "\n",
    "    -- Insertar los nuevos datos actualizados en prueba_miguel\n",
    "    INSERT INTO prueba_miguel (id_employee, replacement_cost, months_left, risk)\n",
    "    SELECT \n",
    "        c.id_employee,\n",
    "        c.income * 12 * 0.645 AS replacement_cost,\n",
    "        p.total_months_in_company - (c.years_company * 12) AS months_left,\n",
    "        (CASE\n",
    "            WHEN (percent_rank() OVER (ORDER BY (p.total_months_in_company - (c.years_company * 12))) <= 0.25) THEN 'Very high'\n",
    "            WHEN (percent_rank() OVER (ORDER BY (p.total_months_in_company - (c.years_company * 12))) <= 0.5) THEN 'High'\n",
    "            WHEN (percent_rank() OVER (ORDER BY (p.total_months_in_company - (c.years_company * 12))) <= 0.75) THEN 'Medium'\n",
    "            ELSE 'Low'\n",
    "        END) AS risk\n",
    "    FROM current_employees c\n",
    "    LEFT JOIN replacement_time r ON (c.role = r.role)\n",
    "    LEFT JOIN predictions p ON (c.id_employee = p.id_employee)\n",
    "    ORDER BY c.id_employee ASC;\n",
    "END;\n",
    "//\n",
    "\n",
    "DELIMITER ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE modelos (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    nombre VARCHAR(255),\n",
    "    modelo MEDIUMBLOB,\n",
    "    scaler MEDIUMBLOB\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
